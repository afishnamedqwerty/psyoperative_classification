Data Collection
Identify Sources: Select social media platforms and forums known for both human and bot activity.
Collect Samples: Gather textual data samples from these platforms. Use API access where
possible. Bot Identification Criteria: Establish criteria or use existing tools to distinguish between
content likely generated by bots versus humans. This may involve metadata analysis or content
analysis


Data collection will consist of two parts - dataset aggregation for training the initial detection bot, and aggregating our test data from twitter

***Pre-training Classifier Dataset***

The pre-training datasets available to us are the following:

`Caverlee`:
Description: Contains bots lured by honeypot accounts and verified human accounts
Data included: Account metadata with associated Botometer scores that reflect a likelihood of the account being a bot.
Metadata for feature extraction: Botomoter classification scores, basic account details (followers, friends, tweet counts), account creation dates, engagement metrics (likes, retweets)

`Cresci-17`:
*Description*: A collection of datasets from Stefano Cresci and others that categorize bots into traditional spambots, social spambots, and fake followers. Each category represents different strategies employed by bots.
*Data included*: Detailed account behaviors and characteristics that are specific to different types of bots.
*Metadata for feature extraction*: Tweet syntax and semantics (for spambots), account interactions and social graphs (for social spambots), follower counts and growth patterns (for fake followers), temporal activity patterns

`Pronbots Dataset`:
*Description*: This dataset focuses on bots that distribute pornographic content and includes characteristics unique to these activities.Each category represents different strategies employed by bots.
*Data included*: Accounts are primarily engaged in spamming links to adult content across various platforms including Twitter.
*Metadata for feature extraction*: URL and domain data linked in tweets, engagement levels (follower/following ratio, tweet engagement), content analysis (presence of specific keywords and hashtags)

`Botwiki and Verified Datasets`:
*Description*: Botwiki is an archive of self-identified bot accounts that are usually benign and creative, while the Verified dataset includes accounts verified by Twitter, ensuring they are genuine human users.
*Data included*: Botwiki features programmatically creative content, and Verified includes typical behaviors of popular human accounts
*Metadata for feature extraction*: Creative content generation patterns, timing, engagement rates, social connections

`Political Bots`:
*Description*: Contains accounts involved in political manipulation or campaigning, identified during specific events.
*Data included*: Tweets and retweets focusing on political topics, hashtags, and significant temporal activity clustering during political events.
*Metadata for feature extraction*: Political engagement (hashtags, mentions), temporal data (activity spikes linked to real-world events), social network characteristics (creation of echo chambers)

`Gilani-17`:
*Description*: Compiled by Zafar Gilani and others, it categorizes accounts based on follower counts into different classes and was annotated for bot-like behaviors by human reviewers.
*Data included*: A balanced mix of human and bot accounts with varied levels of social influence.
*Metadata for feature extraction*: Follower tiers (high, medium, low influence), tweet content and interaction rates, account demographics (bio, location, verification status)


***Testing Model on clustered datasets from Twitter*** 

Following training and testing of the Generative-bot activity model we must run our model on our formatted twitter dataset to discern statistical correlation between bot activity and keywords, time of day, popular user accounts, etc. 

Our clustered dataset is where we can draw inference on what advertising demographics, keywords/current events, or other metadata are correlated with higher bot activity. 

From here we'd need to prove the statement that amongst the twitter activity where we drew our inferences, there are LLMs scraping tweet activity. And of those LLMs scraping tweet activity, whether it be for sentiment analysis or any additional computation, those LLMs (or vLLMs or any model that tokenizes text/image data) could be skewed from the noise or malicious data generated from those botnet campaigns. It's a broad target, but any generative text or image bot campaign that we can prove causes statistical invariance or accuracy degradation in ANY of the features of a model that trains on that data would then set a precedent that bot-generative activity can poison models (multi-modal not just LLM). 

Finally, after allathat we can posit your thesis and dig deeper into what specific amplications of bias (categorically) are affecting the model's output. I feel this will be easier to answer once we appropriately cluster a broad sample of tweet activity with the model;  we can then draw up a knowledge graph on the content from the bots and possibly root out larger botnets by timing data among other features (after parsing out the M⬛U⬛R⬛D⬛E⬛R⬛ I⬛N⬛ B⬛I⬛O low-hanging fruit)


